# Prunnerai 3B V.1.0

> Built from scratch via [Priority Living Labs Model Forge](https://prioritylivinglabs.lovable.app)

## Overview

- **Architecture**: `transformer`
- **Framework**: `pytorch`
- **Target Size**: `2.5`
- **Training Algorithms**: `lora`
- **Status**: `training_ready`

## Repository Structure

```
├── src/
│   ├── model.py              # transformer architecture definition
│   ├── train.py              # Training script (pytorch)
│   ├── dataset.py            # Dataset loading & preprocessing
│   ├── evaluate.py           # Evaluation harness
│   ├── export.py             # Weight export (SafeTensors / GGUF)
│   └── config.py             # Hyperparameter loader
├── models/Prunnerai 3B V.1.0/
│   ├── config.json           # Model DNA & parameters
│   └── system_prompt.md      # System prompt
├── inference/
│   ├── run.py                # Inference (vLLM / Ollama / Transformers)
│   └── requirements.txt      # Inference dependencies
├── data/                     # Training data (JSONL)
├── checkpoints/              # Training checkpoints
├── weights/                  # Exported weights (gitignored)
├── Dockerfile                # GPU training container
├── docker-compose.yml        # Local training orchestration
├── Makefile                  # make train, make eval, make export
└── requirements.txt          # Full training dependencies
```

## Quick Start

### 1. Prepare Data
```bash
# Add your training data
cp your_data.jsonl data/train.jsonl
```

### 2. Train
```bash
# Local
make setup
make train

# Docker (GPU)
make docker-train
```

### 3. Evaluate
```bash
make eval
```

### 4. Export
```bash
make export          # SafeTensors
make export-gguf     # GGUF for llama.cpp / Ollama
```

### 5. Inference
```bash
# After exporting weights
python inference/run.py --backend ollama --prompt "Hello!"
```

## Configuration

See `models/Prunnerai 3B V.1.0/config.json` for full model DNA.

## License

MIT — see [LICENSE](./LICENSE) for details.

---

*Generated by Priority Living Labs Model Forge*
